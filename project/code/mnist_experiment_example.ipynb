{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mnist_classifier import *\n",
    "from mnist_data import *\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = MnistClassifier()\n",
    "d = MnistData(use_data_subset = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Mnist Classifier on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 13s 2ms/step - loss: 0.9745 - acc: 0.6810 - val_loss: 0.3648 - val_acc: 0.8980\n"
     ]
    }
   ],
   "source": [
    "cls.fit(*d.into_fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 581us/step\n",
      "Test loss: 0.3647724571228027\n",
      "Test accuracy: 0.898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3647724571228027, 0.898]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.evaluate(*d.into_evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Mnist Classifier on all data but class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current number of examples per digit -- train:\n",
      " {0: 592, 1: 671, 2: 581, 3: 608, 4: 623, 6: 608, 7: 651, 8: 551, 9: 601}\n",
      "\n",
      "current number of examples per digit -- test:\n",
      " {0: 85, 1: 126, 2: 116, 3: 107, 4: 110, 6: 87, 7: 99, 8: 89, 9: 94}\n"
     ]
    }
   ],
   "source": [
    "# get n_classes from data object. no more global constants\n",
    "n_classes = d.get_num_classes()\n",
    "\n",
    "# we'll just use 5\n",
    "d.set_removed_class(5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5486 samples, validate on 913 samples\n",
      "Epoch 1/1\n",
      "5486/5486 [==============================] - 12s 2ms/step - loss: 0.8754 - acc: 0.7147 - val_loss: 0.3078 - val_acc: 0.9014\n"
     ]
    }
   ],
   "source": [
    "cls.fit(*d.into_fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 697us/step\n",
      "Test loss: 0.28098332381248475\n",
      "Test accuracy: 0.825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28098332381248475, 0.825]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.evaluate(*d.into_evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using n samples of the class removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5506 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "5506/5506 [==============================] - 12s 2ms/step - loss: 0.8685 - acc: 0.7134 - val_loss: 0.4107 - val_acc: 0.7780\n"
     ]
    }
   ],
   "source": [
    "cls.fit(*d.into_fit(n = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 570us/step\n",
      "Test loss: 0.4107179440259933\n",
      "Test accuracy: 0.778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4107179440259933, 0.778]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.evaluate(*d.into_evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using n samples + generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5556 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.8881 - acc: 0.7009 - val_loss: 0.3482 - val_acc: 0.8230\n"
     ]
    }
   ],
   "source": [
    "generated_data = d.get_generated_data_stub()\n",
    "cls.fit(*d.into_fit(n = 20, generated_data = generated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 571us/step\n",
      "Test loss: 0.3481994481086731\n",
      "Test accuracy: 0.823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3481994481086731, 0.823]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.evaluate(*d.into_evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Low Shot Dataset Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note class removed paramater was overriden. re-Run d.set_removed_class() if needed\n"
     ]
    }
   ],
   "source": [
    "lsds = d.to_low_shot_dataset(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mnist_classifier import *\n",
    "from mnist_data import *\n",
    "import numpy as np\n",
    "import random\n",
    "from generator import *\n",
    "\n",
    "cls = MnistClassifier\n",
    "d = MnistData(use_data_subset = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done :tada: dataset for quadruplets data collection saved as *mnist_for_collection*\n",
      "Creating clusters/centroids by 1 jobs\n",
      "Running KMeans to get 10 clusters/centroids for `5`.\n",
      "Running KMeans to get 10 clusters/centroids for `0`.\n",
      "Running KMeans to get 10 clusters/centroids for `4`.\n",
      "Running KMeans to get 10 clusters/centroids for `1`.\n",
      "Running KMeans to get 10 clusters/centroids for `9`.\n",
      "Running KMeans to get 10 clusters/centroids for `2`.\n",
      "Running KMeans to get 10 clusters/centroids for `3`.\n",
      "Running KMeans to get 10 clusters/centroids for `6`.\n",
      "Running KMeans to get 10 clusters/centroids for `7`.\n",
      "Running KMeans to get 10 clusters/centroids for `8`.\n",
      "done to cluster :tada: centroids saved as *mnist_centroids_10_clusters*\n",
      "current number of examples per digit -- train:\n",
      " {0: 592, 1: 671, 2: 581, 3: 608, 4: 623, 5: 514, 6: 608, 7: 651, 8: 551, 9: 601}\n",
      "\n",
      "current number of examples per digit -- test:\n",
      " {0: 85, 1: 126, 2: 116, 3: 107, 4: 110, 5: 87, 6: 87, 7: 99, 8: 89, 9: 94}\n",
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 11s 2ms/step - loss: 0.9692 - acc: 0.6872 - val_loss: 0.3440 - val_acc: 0.9020\n",
      "current number of examples per digit -- train:\n",
      " {1: 671, 2: 581, 3: 608, 4: 623, 5: 514, 6: 608, 7: 651, 8: 551, 9: 601}\n",
      "\n",
      "current number of examples per digit -- test:\n",
      " {1: 126, 2: 116, 3: 107, 4: 110, 5: 87, 6: 87, 7: 99, 8: 89, 9: 94}\n",
      "Train on 5408 samples, validate on 915 samples\n",
      "Epoch 1/1\n",
      "5408/5408 [==============================] - 10s 2ms/step - loss: 0.9395 - acc: 0.6949 - val_loss: 0.5233 - val_acc: 0.8328\n",
      "Classifier was set to NOT trainable!\n",
      "Fitting generator\n",
      "Epoch 1/1\n",
      "7922/7922 [==============================] - 11s 1ms/step - loss: 0.3473 - generator_loss: 0.0953 - classifier_loss: 0.5993 - generator_acc: 0.0086 - classifier_acc: 0.6916\n",
      "current number of examples per digit -- train:\n",
      " {0: 592, 1: 671, 2: 581, 3: 608, 4: 623, 5: 514, 6: 608, 7: 651, 8: 551, 9: 601}\n",
      "\n",
      "current number of examples per digit -- test:\n",
      " {0: 85, 1: 126, 2: 116, 3: 107, 4: 110, 5: 87, 6: 87, 7: 99, 8: 89, 9: 94}\n",
      "Testing the ALL classifier on generated data:\n",
      "(100, 28, 28, 1)\n",
      "> /Users/jonathan.somer/School/Advanced ML/AdvancedMachineLearningCourse/project/code/mnist_classifier.py(64)evaluate()\n",
      "-> score =  self.model.evaluate(x_test, y_test, verbose=1)\n",
      "(Pdb) self.model.evaluate(x_test, y_test, verbose=1)\n",
      "100/100 [==============================] - 0s 596us/step\n",
      "[5.344918632507325, 0.0]\n",
      "(Pdb) self.model.evaluate(x_test, y_test, verbose=1)\n",
      "100/100 [==============================] - 0s 630us/step\n",
      "[5.344918632507325, 0.0]\n",
      "(Pdb) y_test\n",
      "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "(Pdb) self.predict([x_test[0]])\n",
      "*** ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (28, 28, 1)\n",
      "(Pdb) self.predict(x_test[0])\n",
      "*** ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (28, 28, 1)\n",
      "(Pdb) self.predict([x_test[0]])\n",
      "*** ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (28, 28, 1)\n",
      "(Pdb) self.predict(np.array(x_test[0]))\n",
      "*** ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (28, 28, 1)\n",
      "(Pdb) x_test\n",
      "array([[[[0.082467  ],\n",
      "         [0.24457411],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.07423677],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.02835426],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.07499205],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.04574512],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.0135467 ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.02486806],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.12742956],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.18536922],\n",
      "         [0.        ],\n",
      "         [0.00649198],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.0781953 ],\n",
      "         [0.2428024 ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.01223463],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.02042465],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.04274257],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.05226792],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.02304497],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.08258279],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.02671995],\n",
      "         [0.        ],\n",
      "         [0.035475  ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.12499236],\n",
      "         [0.17352802],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.180222  ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.02084697],\n",
      "         [0.02906442],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.1497885 ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.12098195],\n",
      "         [0.        ],\n",
      "         [0.09770241],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.05155785],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.10188442],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.21715647],\n",
      "         [0.1762749 ],\n",
      "         [0.33521187]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.25395757],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.05535092],\n",
      "         [0.03024431],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.00158608]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.00993785],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.08655853],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.04819821],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.12177992],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.20455712],\n",
      "         [0.12882787],\n",
      "         [0.16165793]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.33805978],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.07515297],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.03520078]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.1039058 ],\n",
      "         [0.10127749],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.02934625],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.03922212],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.02036767],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.02052083],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.05172326],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.20743205],\n",
      "         [0.18470097],\n",
      "         [0.3338833 ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.27575928],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.05647562],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.09204113],\n",
      "         [0.10434293],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.14100686],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.01708153],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         ...,\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]]], dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) self.x_train\n",
      "*** AttributeError: 'MnistClassifier' object has no attribute 'x_train'\n",
      "(Pdb) self.predict([x_test[0]])\n",
      "*** ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (28, 28, 1)\n",
      "(Pdb) self.predict(x_test)\n",
      "array([[1.12613803e-02, 7.20420721e-05, 3.80838246e-05, 4.70855413e-03,\n",
      "        4.31079621e-04, 9.64292586e-01, 6.95284165e-04, 1.86667719e-04,\n",
      "        1.76550504e-02, 6.59167883e-04],\n",
      "       [7.23092025e-03, 6.07125767e-05, 3.12057855e-05, 5.78691252e-03,\n",
      "        2.81078246e-04, 9.72521544e-01, 4.30848944e-04, 1.18595883e-04,\n",
      "        1.31044975e-02, 4.33595415e-04],\n",
      "       [1.09370770e-02, 3.69861918e-05, 3.19252576e-05, 4.17025480e-03,\n",
      "        2.15882945e-04, 9.60908353e-01, 3.68521025e-04, 1.25073173e-04,\n",
      "        2.27686297e-02, 4.37159033e-04],\n",
      "       [8.68128985e-03, 5.05191892e-05, 2.51586807e-05, 3.77907511e-03,\n",
      "        3.05109046e-04, 9.71655846e-01, 4.71131410e-04, 1.33895795e-04,\n",
      "        1.44616077e-02, 4.36359871e-04],\n",
      "       [1.00933248e-02, 5.52195270e-05, 3.32485288e-05, 4.41730116e-03,\n",
      "        3.35322053e-04, 9.65428352e-01, 5.07741643e-04, 1.38273797e-04,\n",
      "        1.84809081e-02, 5.10295737e-04],\n",
      "       [9.25515965e-03, 7.12365145e-05, 5.43166643e-05, 9.14449058e-03,\n",
      "        2.62504094e-04, 9.61766899e-01, 4.32280882e-04, 1.50666965e-04,\n",
      "        1.82667132e-02, 5.95716760e-04],\n",
      "       [6.80521317e-03, 6.44334141e-05, 3.53138021e-05, 6.27134601e-03,\n",
      "        2.63916823e-04, 9.74415183e-01, 3.96158517e-04, 1.09998233e-04,\n",
      "        1.12433098e-02, 3.95045150e-04],\n",
      "       [1.08988527e-02, 6.71049711e-05, 4.22453522e-05, 5.08916797e-03,\n",
      "        3.55837081e-04, 9.61779177e-01, 5.43815258e-04, 1.67775317e-04,\n",
      "        2.05509663e-02, 5.05038479e-04],\n",
      "       [8.01056065e-03, 1.88267386e-05, 1.30312283e-05, 1.94375857e-03,\n",
      "        1.66742946e-04, 9.74883795e-01, 2.96761398e-04, 5.04370946e-05,\n",
      "        1.44220283e-02, 1.94045613e-04],\n",
      "       [1.08988630e-02, 6.71050366e-05, 4.22453959e-05, 5.08917216e-03,\n",
      "        3.55837401e-04, 9.61779177e-01, 5.43815782e-04, 1.67775477e-04,\n",
      "        2.05509812e-02, 5.05038886e-04],\n",
      "       [2.49631517e-03, 9.05182533e-05, 4.94267078e-05, 2.62629557e-02,\n",
      "        1.54713300e-04, 9.60655153e-01, 1.95581524e-04, 7.02527323e-05,\n",
      "        9.62340459e-03, 4.01761208e-04],\n",
      "       [2.72727921e-03, 2.96148119e-05, 1.77202601e-05, 9.62501299e-03,\n",
      "        9.45024149e-05, 9.80179191e-01, 1.32593559e-04, 4.08100968e-05,\n",
      "        6.90108584e-03, 2.52273108e-04],\n",
      "       [4.12705820e-03, 1.84024375e-05, 1.05522731e-05, 4.21625469e-03,\n",
      "        9.38907906e-05, 9.82167125e-01, 1.47600687e-04, 4.68424259e-05,\n",
      "        8.94334633e-03, 2.28818681e-04],\n",
      "       [3.89193115e-03, 5.03856973e-05, 2.80642234e-05, 1.02615431e-02,\n",
      "        1.53853718e-04, 9.75675225e-01, 2.35597283e-04, 5.95185229e-05,\n",
      "        9.31896921e-03, 3.24828899e-04],\n",
      "       [4.10661194e-03, 4.20220713e-05, 2.01004950e-05, 7.72748748e-03,\n",
      "        1.54944282e-04, 9.75710094e-01, 2.16932400e-04, 7.55462970e-05,\n",
      "        1.15823355e-02, 3.63960600e-04],\n",
      "       [4.65553021e-03, 1.37285228e-04, 1.01491089e-04, 3.72577943e-02,\n",
      "        2.69533775e-04, 9.42701340e-01, 3.44202184e-04, 1.28314627e-04,\n",
      "        1.35952774e-02, 8.09098186e-04],\n",
      "       [3.57122067e-03, 3.85132953e-05, 1.63022833e-05, 7.17036892e-03,\n",
      "        1.61282762e-04, 9.80158806e-01, 2.19425085e-04, 6.49666836e-05,\n",
      "        8.22546426e-03, 3.73545248e-04],\n",
      "       [3.99975525e-03, 5.18634552e-05, 3.94800663e-05, 1.46831525e-02,\n",
      "        1.55642250e-04, 9.70303774e-01, 2.35262356e-04, 6.15610188e-05,\n",
      "        1.00095645e-02, 4.60001262e-04],\n",
      "       [1.95559952e-03, 2.87787898e-05, 1.47407136e-05, 1.05520282e-02,\n",
      "        8.02004142e-05, 9.81907308e-01, 1.15752671e-04, 2.86727718e-05,\n",
      "        5.11708856e-03, 1.99832226e-04],\n",
      "       [4.43116017e-03, 7.30710526e-05, 4.57652204e-05, 1.57234501e-02,\n",
      "        1.95730579e-04, 9.64908898e-01, 2.76503852e-04, 1.02465106e-04,\n",
      "        1.36401504e-02, 6.02928514e-04],\n",
      "       [5.29603288e-03, 1.10236680e-04, 1.06114987e-03, 1.51659816e-03,\n",
      "        7.75591587e-04, 1.47409411e-02, 9.51492111e-04, 2.60873348e-04,\n",
      "        9.73003328e-01, 2.28373660e-03],\n",
      "       [1.91549473e-02, 2.58475920e-04, 1.29396014e-03, 1.04448758e-02,\n",
      "        1.50285906e-03, 1.38981879e-01, 1.66911422e-03, 5.82268694e-04,\n",
      "        8.21929693e-01, 4.18182276e-03],\n",
      "       [4.69230535e-03, 1.60702795e-04, 2.49733310e-03, 3.13049695e-03,\n",
      "        6.34878234e-04, 1.27033247e-02, 7.21804216e-04, 1.84463439e-04,\n",
      "        9.73707497e-01, 1.56708411e-03],\n",
      "       [8.78987089e-03, 8.84464098e-05, 8.99741950e-04, 1.13559642e-03,\n",
      "        8.61278386e-04, 1.72837712e-02, 1.30632194e-03, 2.43507879e-04,\n",
      "        9.66851294e-01, 2.54013180e-03],\n",
      "       [4.62041702e-03, 1.15816852e-04, 1.29354675e-03, 7.67913763e-04,\n",
      "        7.48692139e-04, 8.13642517e-03, 9.54972580e-04, 2.09962367e-04,\n",
      "        9.81594801e-01, 1.55748462e-03],\n",
      "       [6.57007610e-03, 8.55552862e-05, 1.14008086e-03, 1.31095166e-03,\n",
      "        6.53599447e-04, 1.53858894e-02, 8.36401829e-04, 2.34753825e-04,\n",
      "        9.71803069e-01, 1.97966304e-03],\n",
      "       [6.88615441e-03, 1.50364125e-04, 1.64885458e-03, 2.96287052e-03,\n",
      "        9.31442948e-04, 2.20742114e-02, 1.04072120e-03, 2.36261083e-04,\n",
      "        9.61721241e-01, 2.34780670e-03],\n",
      "       [8.85855686e-03, 1.05241008e-04, 7.26487837e-04, 1.31337345e-03,\n",
      "        1.15002110e-03, 2.78810151e-02, 1.32662535e-03, 2.39235102e-04,\n",
      "        9.55795407e-01, 2.60407571e-03],\n",
      "       [1.00849345e-02, 8.40050125e-05, 5.69746073e-04, 1.97864091e-03,\n",
      "        9.04108456e-04, 5.08036464e-02, 9.93473805e-04, 2.40210735e-04,\n",
      "        9.31972682e-01, 2.36857682e-03],\n",
      "       [8.50460213e-03, 2.60643777e-04, 2.22721463e-03, 7.92109966e-03,\n",
      "        8.54671525e-04, 4.52266224e-02, 9.53149865e-04, 3.20767052e-04,\n",
      "        9.31613445e-01, 2.11777678e-03],\n",
      "       [9.32836086e-02, 6.16311969e-04, 3.24087963e-03, 7.90913962e-03,\n",
      "        4.67246259e-03, 3.58464181e-01, 1.93188246e-02, 9.34495998e-04,\n",
      "        5.06360710e-01, 5.19944867e-03],\n",
      "       [9.41295698e-02, 7.58783368e-04, 1.43791980e-03, 6.33206917e-03,\n",
      "        9.73205641e-03, 5.44739366e-01, 3.17317806e-02, 1.18147593e-03,\n",
      "        3.03540945e-01, 6.41601533e-03],\n",
      "       [4.71837744e-02, 6.01437059e-04, 8.60432512e-04, 1.40410392e-02,\n",
      "        2.75662867e-03, 8.51762474e-01, 8.46887566e-03, 8.04477138e-04,\n",
      "        7.09498003e-02, 2.57105124e-03],\n",
      "       [7.46809542e-02, 9.26924287e-04, 1.79330737e-03, 6.96977321e-03,\n",
      "        8.42382666e-03, 4.24164474e-01, 1.97951403e-02, 1.88155251e-03,\n",
      "        4.53623742e-01, 7.74028618e-03],\n",
      "       [1.17053598e-01, 1.35633687e-03, 6.72629196e-03, 1.21073369e-02,\n",
      "        7.53473118e-03, 3.11542034e-01, 3.85270901e-02, 2.22612196e-03,\n",
      "        4.93711591e-01, 9.21492744e-03],\n",
      "       [9.88402143e-02, 1.41723733e-03, 3.87172820e-03, 1.62557606e-02,\n",
      "        7.56773073e-03, 4.56422836e-01, 2.29566302e-02, 2.65256641e-03,\n",
      "        3.77738476e-01, 1.22768320e-02],\n",
      "       [7.21738264e-02, 9.08818562e-04, 1.20267796e-03, 1.22128483e-02,\n",
      "        6.15216652e-03, 7.41708457e-01, 1.84001867e-02, 1.57585752e-03,\n",
      "        1.40682310e-01, 4.98283422e-03],\n",
      "       [9.02163759e-02, 7.90328078e-04, 2.80583370e-03, 1.50460489e-02,\n",
      "        3.91772063e-03, 5.69429278e-01, 1.20951589e-02, 1.60771515e-03,\n",
      "        2.98286349e-01, 5.80509100e-03],\n",
      "       [6.92487881e-02, 9.87716950e-04, 1.95225456e-03, 2.30413843e-02,\n",
      "        4.04835306e-03, 7.52898514e-01, 1.15256757e-02, 1.43244211e-03,\n",
      "        1.30060315e-01, 4.80453158e-03],\n",
      "       [8.45812261e-02, 5.88059134e-04, 9.60289733e-04, 9.18082241e-03,\n",
      "        5.62243909e-03, 7.02651143e-01, 1.76380239e-02, 1.32040528e-03,\n",
      "        1.71870619e-01, 5.58684953e-03],\n",
      "       [1.60317274e-03, 3.44826694e-05, 6.56588381e-05, 1.50116816e-01,\n",
      "        2.57612628e-05, 8.17685544e-01, 3.23183631e-05, 5.34370483e-05,\n",
      "        3.00088432e-02, 3.73980263e-04],\n",
      "       [1.14957907e-03, 6.65718180e-05, 1.92074440e-04, 4.89732653e-01,\n",
      "        2.02670399e-05, 4.82710540e-01, 2.62826597e-05, 6.65369662e-05,\n",
      "        2.56260894e-02, 4.09398868e-04],\n",
      "       [2.59412220e-03, 1.03043567e-05, 3.27320995e-05, 5.47187552e-02,\n",
      "        1.22957308e-05, 9.13720846e-01, 1.89336806e-05, 3.44083455e-05,\n",
      "        2.86286250e-02, 2.28935620e-04],\n",
      "       [1.11130276e-03, 3.02902354e-05, 9.66893640e-05, 3.17786872e-01,\n",
      "        1.29557584e-05, 6.59812093e-01, 1.71093161e-05, 5.14621242e-05,\n",
      "        2.07510069e-02, 3.30318115e-04],\n",
      "       [1.40236702e-03, 3.95522184e-05, 1.36856092e-04, 3.29999894e-01,\n",
      "        2.06710101e-05, 6.41620755e-01, 2.91897704e-05, 4.49193067e-05,\n",
      "        2.63170172e-02, 3.88797809e-04],\n",
      "       [1.26555166e-03, 2.91598099e-05, 8.01322603e-05, 2.46722624e-01,\n",
      "        1.80765292e-05, 7.25857973e-01, 2.26745815e-05, 4.20029028e-05,\n",
      "        2.56229099e-02, 3.38825048e-04],\n",
      "       [1.96742290e-03, 7.87069657e-05, 2.76993582e-04, 4.21894193e-01,\n",
      "        3.25448382e-05, 5.39297342e-01, 4.69054321e-05, 1.29116408e-04,\n",
      "        3.55539061e-02, 7.22882804e-04],\n",
      "       [2.15012580e-03, 4.35327347e-05, 9.15724377e-05, 1.62740111e-01,\n",
      "        2.91830765e-05, 8.07026505e-01, 3.66059430e-05, 1.13195441e-04,\n",
      "        2.71990336e-02, 5.70169534e-04],\n",
      "       [1.05047517e-03, 2.79455635e-05, 9.68767563e-05, 3.05043936e-01,\n",
      "        1.39108688e-05, 6.74935162e-01, 1.88312242e-05, 2.61249770e-05,\n",
      "        1.85506865e-02, 2.36088730e-04],\n",
      "       [2.57419585e-03, 4.76887508e-05, 1.27597013e-04, 1.97628215e-01,\n",
      "        3.44009459e-05, 7.54840493e-01, 4.50053703e-05, 1.38619958e-04,\n",
      "        4.38280627e-02, 7.35685346e-04],\n",
      "       [2.42799688e-02, 5.47343334e-05, 1.65713296e-04, 2.40657385e-03,\n",
      "        6.16569829e-04, 2.86600411e-01, 5.58653439e-04, 1.17714936e-03,\n",
      "        6.79997921e-01, 4.14234726e-03],\n",
      "       [2.02260595e-02, 6.48787609e-05, 5.01337112e-04, 2.21173931e-03,\n",
      "        5.50349068e-04, 9.17584598e-02, 6.06190530e-04, 2.15475936e-03,\n",
      "        8.74700248e-01, 7.22596934e-03],\n",
      "       [3.24230045e-02, 1.14499824e-04, 3.41115432e-04, 1.11301737e-02,\n",
      "        7.18609779e-04, 5.76787710e-01, 7.13299785e-04, 2.43062456e-03,\n",
      "        3.67478877e-01, 7.86203891e-03],\n",
      "       [1.75547712e-02, 7.24312486e-05, 6.55858428e-04, 2.29127845e-03,\n",
      "        6.65752566e-04, 6.19880669e-02, 8.02428112e-04, 1.52482418e-03,\n",
      "        9.07880008e-01, 6.56455429e-03],\n",
      "       [2.72826776e-02, 4.77502763e-05, 2.09157603e-04, 1.42343866e-03,\n",
      "        9.24734108e-04, 2.00178519e-01, 8.91135191e-04, 1.05603982e-03,\n",
      "        7.62957096e-01, 5.02947671e-03],\n",
      "       [3.03506143e-02, 5.62619352e-05, 1.95168861e-04, 2.08004401e-03,\n",
      "        8.66517599e-04, 2.83472151e-01, 7.88983831e-04, 1.86205236e-03,\n",
      "        6.73125267e-01, 7.20300851e-03],\n",
      "       [3.40639390e-02, 6.63521132e-05, 2.75964790e-04, 3.33612179e-03,\n",
      "        6.46619243e-04, 3.22033703e-01, 5.64901042e-04, 4.43010684e-03,\n",
      "        6.26034677e-01, 8.54766276e-03],\n",
      "       [3.15343402e-02, 4.02221449e-05, 2.27286670e-04, 2.19827890e-03,\n",
      "        4.92649677e-04, 2.50186265e-01, 5.32990030e-04, 1.47248060e-03,\n",
      "        7.08760679e-01, 4.55479883e-03],\n",
      "       [2.62031928e-02, 9.73529095e-05, 3.08633375e-04, 3.24880332e-03,\n",
      "        1.02529791e-03, 2.34656215e-01, 8.50528013e-04, 3.34253535e-03,\n",
      "        7.21333206e-01, 8.93425290e-03],\n",
      "       [2.56442465e-02, 1.08248190e-04, 5.87597198e-04, 4.89181513e-03,\n",
      "        6.99641125e-04, 1.70018598e-01, 7.02615245e-04, 3.99213983e-03,\n",
      "        7.83002198e-01, 1.03529766e-02],\n",
      "       [4.80746385e-03, 4.24016471e-04, 1.56200491e-03, 4.34478283e-01,\n",
      "        7.27167411e-04, 3.00350487e-01, 5.42674039e-04, 4.33629204e-04,\n",
      "        2.49226347e-01, 7.44790491e-03],\n",
      "       [3.40279099e-03, 4.05461411e-04, 1.01008255e-03, 4.11140740e-01,\n",
      "        6.30451483e-04, 3.57257396e-01, 4.67930397e-04, 3.39438964e-04,\n",
      "        2.19555542e-01, 5.79012278e-03],\n",
      "       [2.66646803e-03, 4.28111874e-04, 2.23097042e-03, 6.67953730e-01,\n",
      "        5.34365943e-04, 1.37786746e-01, 3.83756298e-04, 3.40473664e-04,\n",
      "        1.82358101e-01, 5.31726889e-03],\n",
      "       [2.36190809e-03, 3.81882914e-04, 1.92770199e-03, 6.95950806e-01,\n",
      "        4.69834864e-04, 1.64055169e-01, 3.32551252e-04, 2.37989821e-04,\n",
      "        1.30018830e-01, 4.26332699e-03],\n",
      "       [7.66909588e-03, 5.15990658e-04, 2.33256468e-03, 2.77276546e-01,\n",
      "        9.59039317e-04, 2.46400610e-01, 8.12847924e-04, 1.14998699e-03,\n",
      "        4.49316800e-01, 1.35664679e-02],\n",
      "       [3.96170095e-03, 4.53972432e-04, 1.15830055e-03, 3.33299607e-01,\n",
      "        9.23795276e-04, 3.24411511e-01, 5.74016420e-04, 3.90955887e-04,\n",
      "        3.27139288e-01, 7.68684782e-03],\n",
      "       [3.80470208e-03, 2.42647962e-04, 5.46356372e-04, 3.20776016e-01,\n",
      "        4.32977802e-04, 5.67538917e-01, 3.94169154e-04, 2.40083376e-04,\n",
      "        1.01909235e-01, 4.11481131e-03],\n",
      "       [7.68255768e-03, 2.10956248e-04, 3.50175455e-04, 9.58745629e-02,\n",
      "        9.66455147e-04, 6.42545760e-01, 7.25479622e-04, 3.45931243e-04,\n",
      "        2.43023828e-01, 8.27430189e-03],\n",
      "       [6.75422559e-03, 4.73738095e-04, 2.62780418e-03, 2.71068692e-01,\n",
      "        9.67464002e-04, 1.80097744e-01, 7.01402605e-04, 6.38471451e-04,\n",
      "        5.27824938e-01, 8.84547923e-03],\n",
      "       [1.30826992e-03, 4.76989022e-04, 1.84062764e-03, 7.99702704e-01,\n",
      "        3.30617622e-04, 9.35108140e-02, 2.16398388e-04, 1.98835274e-04,\n",
      "        9.94103476e-02, 3.00428667e-03],\n",
      "       [5.30495076e-04, 8.18908960e-03, 3.44163142e-02, 9.35422301e-01,\n",
      "        2.82131397e-04, 8.68446752e-03, 4.05865867e-04, 6.50576141e-04,\n",
      "        1.05367415e-02, 8.82108929e-04],\n",
      "       [2.13807158e-04, 4.48743487e-03, 1.39259445e-02, 9.66855526e-01,\n",
      "        1.30292974e-04, 8.21571238e-03, 1.80762989e-04, 2.24230636e-04,\n",
      "        5.42784715e-03, 3.38441925e-04],\n",
      "       [1.21135125e-03, 1.25138815e-02, 3.99810933e-02, 8.97236526e-01,\n",
      "        8.42556183e-04, 1.52468095e-02, 9.51643276e-04, 1.40374003e-03,\n",
      "        2.84141246e-02, 2.19823164e-03],\n",
      "       [1.68660120e-03, 1.24568418e-02, 4.94610034e-02, 8.83709133e-01,\n",
      "        9.52311442e-04, 1.70808677e-02, 1.19130185e-03, 1.64798135e-03,\n",
      "        2.94895470e-02, 2.32443400e-03],\n",
      "       [6.68008812e-04, 1.20380083e-02, 4.92524765e-02, 9.09381807e-01,\n",
      "        5.15430525e-04, 8.33892543e-03, 5.85318659e-04, 1.16200314e-03,\n",
      "        1.67051274e-02, 1.35295850e-03],\n",
      "       [8.77217448e-04, 3.84115018e-02, 5.71956560e-02, 8.50229561e-01,\n",
      "        9.66008578e-04, 1.59807112e-02, 1.03918812e-03, 1.64288189e-03,\n",
      "        3.20020951e-02, 1.65527372e-03],\n",
      "       [3.50070861e-03, 2.65774261e-02, 4.84558642e-02, 8.03258300e-01,\n",
      "        2.23060371e-03, 4.17183153e-02, 2.61702202e-03, 3.00476467e-03,\n",
      "        6.44982979e-02, 4.13872860e-03],\n",
      "       [3.46725830e-03, 3.39181870e-02, 6.57509565e-02, 8.01760793e-01,\n",
      "        2.09095725e-03, 3.39626595e-02, 2.62810267e-03, 4.13944665e-03,\n",
      "        4.79655452e-02, 4.31608083e-03],\n",
      "       [3.28542519e-04, 6.18178630e-03, 2.03347337e-02, 9.54775810e-01,\n",
      "        1.77692025e-04, 9.68870241e-03, 2.65126961e-04, 3.23952147e-04,\n",
      "        7.47425016e-03, 4.49424726e-04],\n",
      "       [8.48124619e-04, 1.03749093e-02, 3.34213935e-02, 9.17301655e-01,\n",
      "        5.75173821e-04, 1.33122159e-02, 6.92936766e-04, 9.39806399e-04,\n",
      "        2.09961776e-02, 1.53766922e-03],\n",
      "       [1.03469314e-02, 4.19659373e-05, 1.29506714e-03, 3.61028872e-03,\n",
      "        2.14247964e-04, 2.66549140e-02, 4.92331572e-04, 2.37838962e-04,\n",
      "        9.54469800e-01, 2.63658562e-03],\n",
      "       [1.24244513e-02, 6.19699131e-05, 2.01325840e-03, 3.40497820e-03,\n",
      "        3.21844040e-04, 2.17334554e-02, 8.15684558e-04, 4.78733971e-04,\n",
      "        9.54413533e-01, 4.33207676e-03],\n",
      "       [1.59524847e-02, 1.38886957e-04, 3.31687694e-03, 3.11614126e-02,\n",
      "        3.80143116e-04, 8.09772909e-02, 8.38228792e-04, 4.03718150e-04,\n",
      "        8.62525105e-01, 4.30579297e-03],\n",
      "       [8.03594012e-03, 5.43219285e-05, 1.61388691e-03, 6.55415095e-03,\n",
      "        2.66305200e-04, 2.70795412e-02, 5.15855092e-04, 1.96965615e-04,\n",
      "        9.52679813e-01, 3.00324545e-03],\n",
      "       [1.79044027e-02, 7.85567609e-05, 1.97158102e-03, 6.19405694e-03,\n",
      "        3.09610099e-04, 5.01005016e-02, 8.01380549e-04, 4.88984922e-04,\n",
      "        9.18531179e-01, 3.61971417e-03],\n",
      "       [2.03080103e-02, 7.29712046e-05, 1.01607875e-03, 6.23457134e-03,\n",
      "        4.62196534e-04, 9.91247594e-02, 8.13448511e-04, 7.35300244e-04,\n",
      "        8.65484238e-01, 5.74840838e-03],\n",
      "       [1.87706463e-02, 1.21892212e-04, 2.40480411e-03, 2.67717354e-02,\n",
      "        3.63823638e-04, 1.20209716e-01, 8.24122748e-04, 7.13607646e-04,\n",
      "        8.24138165e-01, 5.68149798e-03],\n",
      "       [1.88057385e-02, 3.59553494e-04, 7.51024438e-03, 1.25487655e-01,\n",
      "        4.24779428e-04, 1.11115247e-01, 9.10571660e-04, 1.22981833e-03,\n",
      "        7.28278577e-01, 5.87791298e-03],\n",
      "       [1.31670944e-02, 6.49713911e-05, 1.82970078e-03, 7.71880057e-03,\n",
      "        3.21060914e-04, 4.96170260e-02, 6.77547068e-04, 3.24048742e-04,\n",
      "        9.21802878e-01, 4.47697612e-03],\n",
      "       [2.03660689e-02, 3.01638574e-05, 4.63135715e-04, 3.44026089e-03,\n",
      "        3.32135998e-04, 1.19682707e-01, 6.05517940e-04, 3.05432681e-04,\n",
      "        8.51067662e-01, 3.70682124e-03],\n",
      "       [5.33777820e-05, 1.10141467e-04, 5.67405368e-04, 9.87784982e-01,\n",
      "        1.21778894e-05, 8.89168028e-03, 1.19933657e-05, 1.86777579e-05,\n",
      "        2.41368404e-03, 1.35809794e-04],\n",
      "       [2.81934743e-04, 2.64085917e-04, 5.84784895e-04, 8.94372046e-01,\n",
      "        5.40265137e-05, 9.48095098e-02, 5.13527011e-05, 5.06278629e-05,\n",
      "        9.16022900e-03, 3.71385919e-04],\n",
      "       [7.11614732e-04, 1.95295448e-04, 6.72434457e-04, 8.22516799e-01,\n",
      "        5.57717358e-05, 1.59838572e-01, 6.38120619e-05, 7.58541137e-05,\n",
      "        1.52838333e-02, 5.86028036e-04],\n",
      "       [3.07950359e-05, 5.44206996e-05, 3.16749269e-04, 9.87449646e-01,\n",
      "        6.45490945e-06, 9.98632517e-03, 6.11533824e-06, 7.79304537e-06,\n",
      "        2.07059644e-03, 7.11518805e-05],\n",
      "       [1.49611733e-04, 2.39839341e-04, 6.39114238e-04, 9.61150050e-01,\n",
      "        3.78085497e-05, 3.12853269e-02, 3.30189323e-05, 4.56510679e-05,\n",
      "        6.08556485e-03, 3.33961070e-04],\n",
      "       [3.22658569e-04, 2.46029813e-04, 8.97988793e-04, 9.32387650e-01,\n",
      "        5.11527323e-05, 5.75676784e-02, 5.00764545e-05, 7.37915543e-05,\n",
      "        7.88836461e-03, 5.14559913e-04],\n",
      "       [1.26290892e-04, 8.56483312e-05, 2.39082481e-04, 8.91441405e-01,\n",
      "        1.73176741e-05, 1.03625551e-01, 1.74087454e-05, 1.16159963e-05,\n",
      "        4.31324914e-03, 1.22454134e-04],\n",
      "       [6.72344322e-05, 1.00512043e-04, 5.72011748e-04, 9.84426558e-01,\n",
      "        1.52459243e-05, 1.19810803e-02, 1.54276677e-05, 1.65185629e-05,\n",
      "        2.65362556e-03, 1.51705986e-04],\n",
      "       [6.91463007e-04, 3.82203347e-04, 1.01554429e-03, 8.47182930e-01,\n",
      "        1.02342485e-04, 1.31510720e-01, 9.56573276e-05, 1.24404236e-04,\n",
      "        1.80711448e-02, 8.23572103e-04],\n",
      "       [1.91685867e-05, 6.92234753e-05, 3.42434738e-04, 9.93627191e-01,\n",
      "        5.62718151e-06, 4.81452653e-03, 5.31750584e-06, 5.93468667e-06,\n",
      "        1.05388986e-03, 5.67294192e-05]], dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) np.argmax(self.predict(x_test))\n",
      "993\n",
      "(Pdb) np.argmax(self.predict(x_test), axis=0)\n",
      "array([34, 75, 77, 99, 31, 12, 34, 56, 24, 64])\n",
      "(Pdb) np.argmax(self.predict(x_test), axis=1)\n",
      "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8,\n",
      "       8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 5, 8, 8, 5, 5, 5, 5, 5, 5, 3, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 3, 3, 3, 3, 8, 3,\n",
      "       5, 5, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "       8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "LowShotGenerator.benchmark(Classifier=cls, \n",
    "                           data_object=d,\n",
    "                           dataset_name='mnist',\n",
    "                           n_clusters=10,\n",
    "                           λ = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.x_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "low_shot",
   "language": "python",
   "name": "low_shot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
