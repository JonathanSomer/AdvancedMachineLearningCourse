{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from generator import LowShotGenerator\n",
    "from classifier import Classifier\n",
    "from train import get_trained_classifier_and_data\n",
    "\n",
    "import numpy as np\n",
    "import data_utils as du\n",
    "import collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 20\n",
    "n_files = 12\n",
    "λ = 1.\n",
    "n_samples = 1\n",
    "n_examples = 20\n",
    "disease_name = 'Hernia'\n",
    "all_diseases = list(range(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching data from file #1\n",
      "fetching data from file #2\n",
      "fetching data from file #3\n",
      "fetching data from file #4\n",
      "fetching data from file #5\n",
      "fetching data from file #6\n",
      "fetching data from file #7\n",
      "fetching data from file #8\n",
      "fetching data from file #9\n",
      "fetching data from file #10\n",
      "fetching data from file #11\n",
      "fetching data from file #12\n"
     ]
    }
   ],
   "source": [
    "data_obj = du.get_processed_data(n_files)\n",
    "le = du.get_label_encoder(data_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hernia's label is 7\n",
      "All remaining diseases: 0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14\n"
     ]
    }
   ],
   "source": [
    "disease_label_int = le.transform((disease_name,))[0]\n",
    "print('{0}\\'s label is {1}'.format(disease_name, disease_label_int))\n",
    "\n",
    "unused_diseases = [disease_label_int]\n",
    "diseases_to_remove = [disease_name]\n",
    "\n",
    "diseases = [d for d in all_diseases if d not in unused_diseases]\n",
    "print('All remaining diseases: {0}'.format(', '.join([str(l) for l in diseases])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded classifier and data from files\n",
      "Loaded classifier weights from a saved model\n",
      "Classifier is now non-trainable!\n"
     ]
    }
   ],
   "source": [
    "classifier, X_train, X_test, y_train, y_test = get_trained_classifier_and_data(diseases_to_remove, n_files=n_files)\n",
    "classifier.toggle_trainability()  # make the classifier non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded centroids from file\n"
     ]
    }
   ],
   "source": [
    "quadruplets_data = collect.load_quadruplets(n_clusters=n_clusters, categories=diseases, n_files=n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3146240   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              1050624   \n",
      "=================================================================\n",
      "Total params: 4,459,520\n",
      "Trainable params: 4,459,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Whole model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3146240   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 14)                28686     \n",
      "=================================================================\n",
      "Total params: 4,488,206\n",
      "Trainable params: 4,459,520\n",
      "Non-trainable params: 28,686\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lsg_name = 'lsg_f.{0}_c.{1}_w.{2}'.format(n_files, n_clusters, '.'.join([str(d) for d in unused_diseases]))\n",
    "lsg = LowShotGenerator(classifier.model, quadruplets_data, λ=λ, name=lsg_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting generator\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/10\n",
      "47088/47088 [==============================] - 19s 399us/step - loss: 5.9223 - dense_3_loss: 3.1068 - model_2_loss: 2.8155 - dense_3_acc: 0.4267 - model_2_acc: 0.0750\n",
      "Epoch 2/10\n",
      "47088/47088 [==============================] - 18s 391us/step - loss: 3.1213 - dense_3_loss: 0.4730 - model_2_loss: 2.6484 - dense_3_acc: 0.6574 - model_2_acc: 0.0738\n",
      "Epoch 3/10\n",
      "47088/47088 [==============================] - 19s 395us/step - loss: 3.1185 - dense_3_loss: 0.4727 - model_2_loss: 2.6458 - dense_3_acc: 0.6574 - model_2_acc: 0.0741\n",
      "Epoch 4/10\n",
      "47088/47088 [==============================] - 19s 398us/step - loss: 3.1164 - dense_3_loss: 0.4727 - model_2_loss: 2.6438 - dense_3_acc: 0.6574 - model_2_acc: 0.0773\n",
      "Epoch 5/10\n",
      "47088/47088 [==============================] - 19s 399us/step - loss: 3.1169 - dense_3_loss: 0.4726 - model_2_loss: 2.6442 - dense_3_acc: 0.6574 - model_2_acc: 0.0756\n",
      "Epoch 6/10\n",
      "47088/47088 [==============================] - 19s 395us/step - loss: 3.1144 - dense_3_loss: 0.4726 - model_2_loss: 2.6418 - dense_3_acc: 0.6574 - model_2_acc: 0.0762\n",
      "Epoch 7/10\n",
      "47088/47088 [==============================] - 19s 398us/step - loss: 3.1150 - dense_3_loss: 0.4726 - model_2_loss: 2.6425 - dense_3_acc: 0.6574 - model_2_acc: 0.0751\n",
      "Epoch 8/10\n",
      "47088/47088 [==============================] - 19s 402us/step - loss: 3.1148 - dense_3_loss: 0.4726 - model_2_loss: 2.6422 - dense_3_acc: 0.6574 - model_2_acc: 0.0764\n",
      "Epoch 9/10\n",
      "47088/47088 [==============================] - 20s 420us/step - loss: 3.1141 - dense_3_loss: 0.4726 - model_2_loss: 2.6415 - dense_3_acc: 0.6574 - model_2_acc: 0.0759\n",
      "Epoch 10/10\n",
      "47088/47088 [==============================] - 19s 406us/step - loss: 3.1133 - dense_3_loss: 0.4725 - model_2_loss: 2.6408 - dense_3_acc: 0.6574 - model_2_acc: 0.0758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f48fc135080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded centroids from file\n"
     ]
    }
   ],
   "source": [
    "unused_data = collect.load_quadruplets(n_clusters=n_clusters, categories=all_diseases, n_files=n_files)\n",
    "quadruplets, centroids, cat_to_vectors, original_shape = unused_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 20 examples from 1 samples of 7\n"
     ]
    }
   ],
   "source": [
    "print('Generating {0} examples from {1} samples of {2}'.format(n_examples, n_samples, disease_label_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 1 samples\n",
      "Testing on 109 samples\n"
     ]
    }
   ],
   "source": [
    "# get all data of all diseases\n",
    "X, y = du.get_features_and_labels(data_obj)\n",
    "X_train, X_test, y_train, y_test = du.get_train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# remove the data of the disease\n",
    "mask = ~(y_test[:, disease_label_int] == 1.0)\n",
    "y_test_sub = y_test[mask]\n",
    "X_test_sub = X_test[mask]\n",
    "\n",
    "mask = ~(y_train[:, disease_label_int] == 1.0)\n",
    "y_train_sub = y_train[mask]\n",
    "X_train_sub = X_train[mask]\n",
    "\n",
    "# keep the data of the disease\n",
    "mask = (y_test[:, disease_label_int] == 1.0)\n",
    "y_test_disease = y_test[mask]\n",
    "X_test_disease = X_test[mask]\n",
    "\n",
    "mask = (y_train[:, disease_label_int] == 1.0)\n",
    "y_train_disease = y_train[mask]\n",
    "X_train_disease = X_train[mask]\n",
    "\n",
    "y_disease = np.concatenate((y_train_disease, y_test_disease))\n",
    "X_disease = np.concatenate((X_train_disease, X_test_disease))\n",
    "\n",
    "# split the data of the disease (should train only with n_samples)\n",
    "mask = np.ones(len(y_disease), dtype=bool)\n",
    "mask[list(range(n_samples))] = False\n",
    "y_train_disease, y_test_disease = y_disease[~mask], y_disease[mask]\n",
    "X_train_disease, X_test_disease = X_disease[~mask], X_disease[mask]\n",
    "\n",
    "print('Training with {0} samples'.format(len(X_train_disease)))\n",
    "print('Testing on {0} samples'.format(len(X_test_disease)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73881 samples, validate on 8209 samples\n",
      "Epoch 1/100\n",
      "73881/73881 [==============================] - 6s 78us/step - loss: 2.3993 - acc: 0.1395 - val_loss: 8.7422 - val_acc: 0.1722\n",
      "Epoch 2/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 2.2378 - acc: 0.1634 - val_loss: 9.5380 - val_acc: 0.1663\n",
      "Epoch 3/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 2.1791 - acc: 0.1712 - val_loss: 10.2062 - val_acc: 0.2228\n",
      "Epoch 4/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 2.1377 - acc: 0.1763 - val_loss: 10.7277 - val_acc: 0.2273\n",
      "Epoch 5/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 2.1062 - acc: 0.1799 - val_loss: 11.3148 - val_acc: 0.1844\n",
      "Epoch 6/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 2.0823 - acc: 0.1849 - val_loss: 11.7909 - val_acc: 0.1370\n",
      "Epoch 7/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 2.0591 - acc: 0.1878 - val_loss: 12.3781 - val_acc: 0.1967\n",
      "Epoch 8/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 2.0388 - acc: 0.1923 - val_loss: 12.8911 - val_acc: 0.1669\n",
      "Epoch 9/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 2.0210 - acc: 0.1917 - val_loss: 12.9132 - val_acc: 0.1980\n",
      "Epoch 10/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 2.0039 - acc: 0.1937 - val_loss: 12.8954 - val_acc: 0.1870\n",
      "Epoch 11/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 1.9874 - acc: 0.1967 - val_loss: 12.8773 - val_acc: 0.1664\n",
      "Epoch 12/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.9740 - acc: 0.1973 - val_loss: 12.8929 - val_acc: 0.2311\n",
      "Epoch 13/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.9621 - acc: 0.2008 - val_loss: 12.8885 - val_acc: 0.1571\n",
      "Epoch 14/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.9500 - acc: 0.2036 - val_loss: 12.8756 - val_acc: 0.1892\n",
      "Epoch 15/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.9373 - acc: 0.2048 - val_loss: 12.8702 - val_acc: 0.2220\n",
      "Epoch 16/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.9261 - acc: 0.2055 - val_loss: 12.8886 - val_acc: 0.1740\n",
      "Epoch 17/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.9173 - acc: 0.2076 - val_loss: 12.8639 - val_acc: 0.1623\n",
      "Epoch 18/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.9026 - acc: 0.2097 - val_loss: 12.8706 - val_acc: 0.1317\n",
      "Epoch 19/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.8931 - acc: 0.2096 - val_loss: 12.8915 - val_acc: 0.2098\n",
      "Epoch 20/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.8850 - acc: 0.2112 - val_loss: 12.8829 - val_acc: 0.2206\n",
      "Epoch 21/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.8776 - acc: 0.2131 - val_loss: 12.8709 - val_acc: 0.1322\n",
      "Epoch 22/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.8689 - acc: 0.2093 - val_loss: 12.8681 - val_acc: 0.1883\n",
      "Epoch 23/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.8602 - acc: 0.2118 - val_loss: 12.8647 - val_acc: 0.2446\n",
      "Epoch 24/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.8514 - acc: 0.2155 - val_loss: 12.8752 - val_acc: 0.1811\n",
      "Epoch 25/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.8424 - acc: 0.2131 - val_loss: 12.8767 - val_acc: 0.1707\n",
      "Epoch 26/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.8372 - acc: 0.2178 - val_loss: 12.8700 - val_acc: 0.2170\n",
      "Epoch 27/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.8276 - acc: 0.2194 - val_loss: 12.8654 - val_acc: 0.1713\n",
      "Epoch 28/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.8189 - acc: 0.2168 - val_loss: 12.8673 - val_acc: 0.1729\n",
      "Epoch 29/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.8128 - acc: 0.2208 - val_loss: 12.8727 - val_acc: 0.1712\n",
      "Epoch 30/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 1.8083 - acc: 0.2184 - val_loss: 12.8732 - val_acc: 0.1932\n",
      "Epoch 31/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.8006 - acc: 0.2214 - val_loss: 12.8717 - val_acc: 0.2114\n",
      "Epoch 32/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.7939 - acc: 0.2220 - val_loss: 12.8856 - val_acc: 0.1486\n",
      "Epoch 33/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.7870 - acc: 0.2218 - val_loss: 12.8611 - val_acc: 0.2490\n",
      "Epoch 34/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.7819 - acc: 0.2239 - val_loss: 12.8706 - val_acc: 0.1617\n",
      "Epoch 35/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.7742 - acc: 0.2222 - val_loss: 12.8661 - val_acc: 0.2157\n",
      "Epoch 36/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.7705 - acc: 0.2269 - val_loss: 12.8738 - val_acc: 0.2114\n",
      "Epoch 37/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.7630 - acc: 0.2260 - val_loss: 12.8681 - val_acc: 0.1888\n",
      "Epoch 38/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.7574 - acc: 0.2265 - val_loss: 12.8872 - val_acc: 0.1776\n",
      "Epoch 39/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.7517 - acc: 0.2268 - val_loss: 12.8956 - val_acc: 0.2221\n",
      "Epoch 40/100\n",
      "73881/73881 [==============================] - 6s 76us/step - loss: 1.7474 - acc: 0.2281 - val_loss: 12.8773 - val_acc: 0.1830\n",
      "Epoch 41/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.7407 - acc: 0.2293 - val_loss: 12.8748 - val_acc: 0.1670\n",
      "Epoch 42/100\n",
      "73881/73881 [==============================] - 6s 84us/step - loss: 1.7358 - acc: 0.2282 - val_loss: 12.8884 - val_acc: 0.1704\n",
      "Epoch 43/100\n",
      "73881/73881 [==============================] - 7s 93us/step - loss: 1.7288 - acc: 0.2293 - val_loss: 12.8890 - val_acc: 0.1859\n",
      "Epoch 44/100\n",
      "73881/73881 [==============================] - 7s 94us/step - loss: 1.7245 - acc: 0.2303 - val_loss: 12.8650 - val_acc: 0.1811\n",
      "Epoch 45/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.7206 - acc: 0.2284 - val_loss: 12.8850 - val_acc: 0.2165\n",
      "Epoch 46/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.7155 - acc: 0.2282 - val_loss: 12.8734 - val_acc: 0.2206\n",
      "Epoch 47/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 1.7100 - acc: 0.2313 - val_loss: 12.8706 - val_acc: 0.1831\n",
      "Epoch 48/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.7062 - acc: 0.2320 - val_loss: 12.8813 - val_acc: 0.1932\n",
      "Epoch 49/100\n",
      "73881/73881 [==============================] - 6s 76us/step - loss: 1.6994 - acc: 0.2329 - val_loss: 12.8842 - val_acc: 0.2181\n",
      "Epoch 50/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.6973 - acc: 0.2322 - val_loss: 12.8775 - val_acc: 0.2011\n",
      "Epoch 51/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.6922 - acc: 0.2331 - val_loss: 12.8666 - val_acc: 0.2017\n",
      "Epoch 52/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.6872 - acc: 0.2344 - val_loss: 12.8912 - val_acc: 0.2363\n",
      "Epoch 53/100\n",
      "73881/73881 [==============================] - 6s 76us/step - loss: 1.6856 - acc: 0.2359 - val_loss: 12.8852 - val_acc: 0.1865\n",
      "Epoch 54/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.6793 - acc: 0.2338 - val_loss: 12.8929 - val_acc: 0.2160\n",
      "Epoch 55/100\n",
      "73881/73881 [==============================] - 6s 76us/step - loss: 1.6750 - acc: 0.2354 - val_loss: 12.8855 - val_acc: 0.1937\n",
      "Epoch 56/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.6711 - acc: 0.2345 - val_loss: 12.8921 - val_acc: 0.2232\n",
      "Epoch 57/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.6661 - acc: 0.2375 - val_loss: 12.8833 - val_acc: 0.1995\n",
      "Epoch 58/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.6618 - acc: 0.2367 - val_loss: 12.8767 - val_acc: 0.2394\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73881/73881 [==============================] - 5s 73us/step - loss: 1.6597 - acc: 0.2373 - val_loss: 12.8886 - val_acc: 0.2120\n",
      "Epoch 60/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 1.6553 - acc: 0.2398 - val_loss: 12.8994 - val_acc: 0.1673\n",
      "Epoch 61/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.6527 - acc: 0.2384 - val_loss: 12.8910 - val_acc: 0.1776\n",
      "Epoch 62/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.6467 - acc: 0.2379 - val_loss: 12.8798 - val_acc: 0.2061\n",
      "Epoch 63/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.6443 - acc: 0.2377 - val_loss: 12.9058 - val_acc: 0.2123\n",
      "Epoch 64/100\n",
      "73881/73881 [==============================] - 6s 76us/step - loss: 1.6422 - acc: 0.2393 - val_loss: 12.9025 - val_acc: 0.1798\n",
      "Epoch 65/100\n",
      "73881/73881 [==============================] - 6s 74us/step - loss: 1.6363 - acc: 0.2391 - val_loss: 12.8894 - val_acc: 0.1986\n",
      "Epoch 66/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.6335 - acc: 0.2380 - val_loss: 12.9035 - val_acc: 0.1978\n",
      "Epoch 67/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.6300 - acc: 0.2402 - val_loss: 12.8926 - val_acc: 0.1993\n",
      "Epoch 68/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.6265 - acc: 0.2414 - val_loss: 12.9076 - val_acc: 0.1638\n",
      "Epoch 69/100\n",
      "73881/73881 [==============================] - 7s 88us/step - loss: 1.6230 - acc: 0.2403 - val_loss: 12.8946 - val_acc: 0.1828\n",
      "Epoch 70/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.6202 - acc: 0.2426 - val_loss: 12.9043 - val_acc: 0.1876\n",
      "Epoch 71/100\n",
      "73881/73881 [==============================] - 6s 86us/step - loss: 1.6166 - acc: 0.2412 - val_loss: 12.9047 - val_acc: 0.2122\n",
      "Epoch 72/100\n",
      "73881/73881 [==============================] - 6s 76us/step - loss: 1.6129 - acc: 0.2401 - val_loss: 12.9093 - val_acc: 0.2224\n",
      "Epoch 73/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 1.6115 - acc: 0.2423 - val_loss: 12.9124 - val_acc: 0.1972\n",
      "Epoch 74/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.6058 - acc: 0.2425 - val_loss: 12.9264 - val_acc: 0.2232\n",
      "Epoch 75/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 1.6026 - acc: 0.2433 - val_loss: 12.9306 - val_acc: 0.1681\n",
      "Epoch 76/100\n",
      "73881/73881 [==============================] - 5s 73us/step - loss: 1.6005 - acc: 0.2400 - val_loss: 12.9047 - val_acc: 0.2055\n",
      "Epoch 77/100\n",
      "73881/73881 [==============================] - 5s 74us/step - loss: 1.5957 - acc: 0.2441 - val_loss: 12.9285 - val_acc: 0.2238\n",
      "Epoch 78/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.5935 - acc: 0.2453 - val_loss: 12.9244 - val_acc: 0.1934\n",
      "Epoch 79/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.5921 - acc: 0.2452 - val_loss: 12.9036 - val_acc: 0.2064\n",
      "Epoch 80/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.5904 - acc: 0.2448 - val_loss: 12.9010 - val_acc: 0.1943\n",
      "Epoch 81/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.5861 - acc: 0.2457 - val_loss: 12.9221 - val_acc: 0.1413\n",
      "Epoch 82/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.5827 - acc: 0.2448 - val_loss: 12.9152 - val_acc: 0.1858\n",
      "Epoch 83/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.5805 - acc: 0.2452 - val_loss: 12.9121 - val_acc: 0.1936\n",
      "Epoch 84/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.5770 - acc: 0.2457 - val_loss: 12.9246 - val_acc: 0.2282\n",
      "Epoch 85/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.5743 - acc: 0.2458 - val_loss: 12.9362 - val_acc: 0.1892\n",
      "Epoch 86/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.5715 - acc: 0.2464 - val_loss: 12.9596 - val_acc: 0.1956\n",
      "Epoch 87/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.5699 - acc: 0.2458 - val_loss: 12.9342 - val_acc: 0.2086\n",
      "Epoch 88/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.5668 - acc: 0.2460 - val_loss: 12.9241 - val_acc: 0.1768\n",
      "Epoch 89/100\n",
      "73881/73881 [==============================] - 5s 70us/step - loss: 1.5631 - acc: 0.2462 - val_loss: 12.9410 - val_acc: 0.2344\n",
      "Epoch 90/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.5606 - acc: 0.2480 - val_loss: 12.9352 - val_acc: 0.1945\n",
      "Epoch 91/100\n",
      "73881/73881 [==============================] - 5s 69us/step - loss: 1.5598 - acc: 0.2494 - val_loss: 12.9171 - val_acc: 0.2064\n",
      "Epoch 92/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.5558 - acc: 0.2480 - val_loss: 12.9535 - val_acc: 0.1898\n",
      "Epoch 93/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.5537 - acc: 0.2471 - val_loss: 12.9333 - val_acc: 0.1899\n",
      "Epoch 94/100\n",
      "73881/73881 [==============================] - 5s 71us/step - loss: 1.5509 - acc: 0.2478 - val_loss: 12.9289 - val_acc: 0.1782\n",
      "Epoch 95/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.5482 - acc: 0.2477 - val_loss: 12.9438 - val_acc: 0.2193\n",
      "Epoch 96/100\n",
      "73881/73881 [==============================] - 5s 72us/step - loss: 1.5451 - acc: 0.2489 - val_loss: 12.9594 - val_acc: 0.2382\n",
      "Epoch 97/100\n",
      "73881/73881 [==============================] - 6s 75us/step - loss: 1.5431 - acc: 0.2466 - val_loss: 12.9452 - val_acc: 0.2022\n",
      "Epoch 98/100\n",
      "73881/73881 [==============================] - 6s 74us/step - loss: 1.5406 - acc: 0.2500 - val_loss: 12.9474 - val_acc: 0.2289\n",
      "Epoch 99/100\n",
      "73881/73881 [==============================] - 7s 95us/step - loss: 1.5398 - acc: 0.2488 - val_loss: 12.9529 - val_acc: 0.1782\n",
      "Epoch 100/100\n",
      "73881/73881 [==============================] - 7s 94us/step - loss: 1.5350 - acc: 0.2484 - val_loss: 12.9596 - val_acc: 0.2161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f48f11fe080>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, try to train with only n_samples of the disease and the rest samples of allother diseases\n",
    "X_train, y_train = np.concatenate((X_train_sub, X_train_disease)), np.concatenate((y_train_sub, y_train_disease))\n",
    "\n",
    "classifier = Classifier(trainable=True, n_classes=15)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9125/9125 [==============================] - 0s 39us/step\n",
      "accuracy for regular diseases is 0.2127123287671233\n",
      "109/109 [==============================] - 0s 72us/step\n",
      "accuracy for novel disease 7 without generated examples is 0.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = classifier.evaluate(X_test_sub, y_test_sub)\n",
    "print('accuracy for regular diseases is {0}'.format(acc))\n",
    "\n",
    "loss, acc = classifier.evaluate(X_test_disease, y_test_disease)\n",
    "print('accuracy for novel disease {0} without generated examples is {1}'.format(disease_label_int, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, generating new examples and concat them to the n_samples samples\n",
    "new_examples = [lsg.generate(ϕ, n_new=(n_examples - n_samples) // n_samples) for ϕ in X_train_disease]\n",
    "X_train_disease = np.concatenate([X_train_disease] + new_examples)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def onehot_encode(y, n_classes=None):\n",
    "    yy = y.reshape(-1, 1)\n",
    "    enc = OneHotEncoder(n_values=n_classes) if n_classes else OneHotEncoder()\n",
    "    enc.fit(yy)\n",
    "    one_hot_labels = enc.transform(yy).toarray()\n",
    "    return one_hot_labels\n",
    "\n",
    "y_train_disease = onehot_encode(np.array([disease_label_int for x in X_train_disease]), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82089, 15) (20, 15)\n",
      "Train on 73898 samples, validate on 8211 samples\n",
      "Epoch 1/100\n",
      "73898/73898 [==============================] - 5s 74us/step - loss: 2.4020 - acc: 0.1281 - val_loss: 4.9393 - val_acc: 0.1521\n",
      "Epoch 2/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 2.2429 - acc: 0.1596 - val_loss: 5.0925 - val_acc: 0.1510\n",
      "Epoch 3/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 2.1852 - acc: 0.1718 - val_loss: 5.2195 - val_acc: 0.2107\n",
      "Epoch 4/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 2.1422 - acc: 0.1784 - val_loss: 5.3376 - val_acc: 0.2301\n",
      "Epoch 5/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 2.1136 - acc: 0.1813 - val_loss: 5.4491 - val_acc: 0.1703\n",
      "Epoch 6/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 2.0852 - acc: 0.1848 - val_loss: 5.5945 - val_acc: 0.2124\n",
      "Epoch 7/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 2.0620 - acc: 0.1861 - val_loss: 5.7059 - val_acc: 0.2038\n",
      "Epoch 8/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 2.0419 - acc: 0.1894 - val_loss: 5.8159 - val_acc: 0.1854\n",
      "Epoch 9/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 2.0248 - acc: 0.1934 - val_loss: 5.9081 - val_acc: 0.2259\n",
      "Epoch 10/100\n",
      "73898/73898 [==============================] - 5s 72us/step - loss: 2.0070 - acc: 0.1957 - val_loss: 6.0157 - val_acc: 0.2101\n",
      "Epoch 11/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.9913 - acc: 0.1982 - val_loss: 6.1302 - val_acc: 0.1425\n",
      "Epoch 12/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.9784 - acc: 0.1980 - val_loss: 6.2280 - val_acc: 0.2080\n",
      "Epoch 13/100\n",
      "73898/73898 [==============================] - 5s 72us/step - loss: 1.9653 - acc: 0.2016 - val_loss: 6.3408 - val_acc: 0.2104\n",
      "Epoch 14/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.9487 - acc: 0.2005 - val_loss: 6.4682 - val_acc: 0.1499\n",
      "Epoch 15/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.9397 - acc: 0.2034 - val_loss: 6.5450 - val_acc: 0.2119\n",
      "Epoch 16/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.9281 - acc: 0.2053 - val_loss: 6.6760 - val_acc: 0.1740\n",
      "Epoch 17/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.9196 - acc: 0.2071 - val_loss: 6.7724 - val_acc: 0.2090\n",
      "Epoch 18/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.9063 - acc: 0.2077 - val_loss: 6.8683 - val_acc: 0.1817\n",
      "Epoch 19/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.8968 - acc: 0.2097 - val_loss: 6.9625 - val_acc: 0.1656\n",
      "Epoch 20/100\n",
      "73898/73898 [==============================] - 5s 68us/step - loss: 1.8870 - acc: 0.2066 - val_loss: 7.0470 - val_acc: 0.2372\n",
      "Epoch 21/100\n",
      "73898/73898 [==============================] - 5s 68us/step - loss: 1.8791 - acc: 0.2114 - val_loss: 7.1129 - val_acc: 0.1835\n",
      "Epoch 22/100\n",
      "73898/73898 [==============================] - 5s 67us/step - loss: 1.8710 - acc: 0.2125 - val_loss: 7.1797 - val_acc: 0.1812\n",
      "Epoch 23/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.8636 - acc: 0.2143 - val_loss: 7.2164 - val_acc: 0.2270\n",
      "Epoch 24/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.8516 - acc: 0.2135 - val_loss: 7.2888 - val_acc: 0.1936\n",
      "Epoch 25/100\n",
      "73898/73898 [==============================] - 5s 68us/step - loss: 1.8449 - acc: 0.2161 - val_loss: 7.3182 - val_acc: 0.1785\n",
      "Epoch 26/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.8377 - acc: 0.2160 - val_loss: 7.3490 - val_acc: 0.2234\n",
      "Epoch 27/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.8305 - acc: 0.2148 - val_loss: 7.3848 - val_acc: 0.2156\n",
      "Epoch 28/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.8235 - acc: 0.2147 - val_loss: 7.4030 - val_acc: 0.2587\n",
      "Epoch 29/100\n",
      "73898/73898 [==============================] - 5s 68us/step - loss: 1.8145 - acc: 0.2200 - val_loss: 7.4359 - val_acc: 0.1677\n",
      "Epoch 30/100\n",
      "73898/73898 [==============================] - 5s 68us/step - loss: 1.8072 - acc: 0.2190 - val_loss: 7.4624 - val_acc: 0.2103\n",
      "Epoch 31/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.8006 - acc: 0.2200 - val_loss: 7.4943 - val_acc: 0.1944\n",
      "Epoch 32/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.7954 - acc: 0.2213 - val_loss: 7.5039 - val_acc: 0.1707\n",
      "Epoch 33/100\n",
      "73898/73898 [==============================] - 5s 67us/step - loss: 1.7885 - acc: 0.2197 - val_loss: 7.5352 - val_acc: 0.1695\n",
      "Epoch 34/100\n",
      "73898/73898 [==============================] - 5s 68us/step - loss: 1.7826 - acc: 0.2225 - val_loss: 7.5412 - val_acc: 0.2162\n",
      "Epoch 35/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.7765 - acc: 0.2222 - val_loss: 7.5505 - val_acc: 0.2131\n",
      "Epoch 36/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.7691 - acc: 0.2229 - val_loss: 7.5776 - val_acc: 0.1939\n",
      "Epoch 37/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.7652 - acc: 0.2253 - val_loss: 7.5983 - val_acc: 0.1867\n",
      "Epoch 38/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.7592 - acc: 0.2254 - val_loss: 7.6060 - val_acc: 0.2109\n",
      "Epoch 39/100\n",
      "73898/73898 [==============================] - 6s 85us/step - loss: 1.7547 - acc: 0.2252 - val_loss: 7.6178 - val_acc: 0.1626\n",
      "Epoch 40/100\n",
      "73898/73898 [==============================] - 6s 85us/step - loss: 1.7474 - acc: 0.2243 - val_loss: 7.6378 - val_acc: 0.2236\n",
      "Epoch 41/100\n",
      "73898/73898 [==============================] - 6s 83us/step - loss: 1.7435 - acc: 0.2277 - val_loss: 7.6751 - val_acc: 0.2192\n",
      "Epoch 42/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.7361 - acc: 0.2263 - val_loss: 7.6668 - val_acc: 0.1832\n",
      "Epoch 43/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.7324 - acc: 0.2272 - val_loss: 7.6945 - val_acc: 0.2107\n",
      "Epoch 44/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.7284 - acc: 0.2273 - val_loss: 7.6976 - val_acc: 0.1975\n",
      "Epoch 45/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.7215 - acc: 0.2322 - val_loss: 7.7116 - val_acc: 0.2178\n",
      "Epoch 46/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.7180 - acc: 0.2285 - val_loss: 7.7236 - val_acc: 0.1661\n",
      "Epoch 47/100\n",
      "73898/73898 [==============================] - 5s 72us/step - loss: 1.7130 - acc: 0.2294 - val_loss: 7.7282 - val_acc: 0.1837\n",
      "Epoch 48/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.7077 - acc: 0.2298 - val_loss: 7.7604 - val_acc: 0.2386\n",
      "Epoch 49/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.7035 - acc: 0.2316 - val_loss: 7.7599 - val_acc: 0.1979\n",
      "Epoch 50/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6975 - acc: 0.2321 - val_loss: 7.7668 - val_acc: 0.1734\n",
      "Epoch 51/100\n",
      "73898/73898 [==============================] - 5s 68us/step - loss: 1.6934 - acc: 0.2325 - val_loss: 7.7943 - val_acc: 0.1565\n",
      "Epoch 52/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6921 - acc: 0.2321 - val_loss: 7.7909 - val_acc: 0.1934\n",
      "Epoch 53/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6843 - acc: 0.2348 - val_loss: 7.8125 - val_acc: 0.2164\n",
      "Epoch 54/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.6805 - acc: 0.2333 - val_loss: 7.8370 - val_acc: 0.1757\n",
      "Epoch 55/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.6787 - acc: 0.2353 - val_loss: 7.8230 - val_acc: 0.2046\n",
      "Epoch 56/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.6727 - acc: 0.2342 - val_loss: 7.8388 - val_acc: 0.1728\n",
      "Epoch 57/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.6688 - acc: 0.2341 - val_loss: 7.8591 - val_acc: 0.1951\n",
      "Epoch 58/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6658 - acc: 0.2357 - val_loss: 7.8557 - val_acc: 0.1779\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73898/73898 [==============================] - 5s 72us/step - loss: 1.6624 - acc: 0.2344 - val_loss: 7.8938 - val_acc: 0.2678\n",
      "Epoch 60/100\n",
      "73898/73898 [==============================] - 7s 92us/step - loss: 1.6585 - acc: 0.2369 - val_loss: 7.8704 - val_acc: 0.1925\n",
      "Epoch 61/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.6538 - acc: 0.2373 - val_loss: 7.8839 - val_acc: 0.1829\n",
      "Epoch 62/100\n",
      "73898/73898 [==============================] - 6s 75us/step - loss: 1.6489 - acc: 0.2357 - val_loss: 7.9032 - val_acc: 0.1767\n",
      "Epoch 63/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.6447 - acc: 0.2378 - val_loss: 7.9065 - val_acc: 0.1644\n",
      "Epoch 64/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.6400 - acc: 0.2373 - val_loss: 7.9341 - val_acc: 0.2117\n",
      "Epoch 65/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6385 - acc: 0.2404 - val_loss: 7.9437 - val_acc: 0.1823\n",
      "Epoch 66/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.6342 - acc: 0.2368 - val_loss: 7.9394 - val_acc: 0.2050\n",
      "Epoch 67/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.6304 - acc: 0.2394 - val_loss: 7.9688 - val_acc: 0.2086\n",
      "Epoch 68/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.6273 - acc: 0.2394 - val_loss: 7.9460 - val_acc: 0.1549\n",
      "Epoch 69/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6255 - acc: 0.2401 - val_loss: 7.9629 - val_acc: 0.1800\n",
      "Epoch 70/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6215 - acc: 0.2408 - val_loss: 7.9939 - val_acc: 0.1988\n",
      "Epoch 71/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.6186 - acc: 0.2406 - val_loss: 7.9890 - val_acc: 0.1510\n",
      "Epoch 72/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6134 - acc: 0.2396 - val_loss: 7.9873 - val_acc: 0.1905\n",
      "Epoch 73/100\n",
      "73898/73898 [==============================] - 5s 73us/step - loss: 1.6124 - acc: 0.2394 - val_loss: 8.0119 - val_acc: 0.1827\n",
      "Epoch 74/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.6087 - acc: 0.2411 - val_loss: 8.0215 - val_acc: 0.2086\n",
      "Epoch 75/100\n",
      "73898/73898 [==============================] - 5s 72us/step - loss: 1.6055 - acc: 0.2418 - val_loss: 8.0296 - val_acc: 0.2101\n",
      "Epoch 76/100\n",
      "73898/73898 [==============================] - 5s 72us/step - loss: 1.6018 - acc: 0.2432 - val_loss: 8.0416 - val_acc: 0.2024\n",
      "Epoch 77/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.5974 - acc: 0.2425 - val_loss: 8.0619 - val_acc: 0.1883\n",
      "Epoch 78/100\n",
      "73898/73898 [==============================] - 5s 72us/step - loss: 1.5963 - acc: 0.2423 - val_loss: 8.0631 - val_acc: 0.1650\n",
      "Epoch 79/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5941 - acc: 0.2431 - val_loss: 8.0523 - val_acc: 0.1849\n",
      "Epoch 80/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.5891 - acc: 0.2418 - val_loss: 8.0689 - val_acc: 0.2061\n",
      "Epoch 81/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5863 - acc: 0.2449 - val_loss: 8.0815 - val_acc: 0.1517\n",
      "Epoch 82/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5849 - acc: 0.2440 - val_loss: 8.0869 - val_acc: 0.2133\n",
      "Epoch 83/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5820 - acc: 0.2449 - val_loss: 8.1017 - val_acc: 0.1798\n",
      "Epoch 84/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5794 - acc: 0.2447 - val_loss: 8.1049 - val_acc: 0.1882\n",
      "Epoch 85/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5748 - acc: 0.2446 - val_loss: 8.1260 - val_acc: 0.2052\n",
      "Epoch 86/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.5721 - acc: 0.2446 - val_loss: 8.1261 - val_acc: 0.1743\n",
      "Epoch 87/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.5688 - acc: 0.2452 - val_loss: 8.1326 - val_acc: 0.1857\n",
      "Epoch 88/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5669 - acc: 0.2449 - val_loss: 8.1364 - val_acc: 0.1672\n",
      "Epoch 89/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.5639 - acc: 0.2463 - val_loss: 8.1861 - val_acc: 0.1608\n",
      "Epoch 90/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.5631 - acc: 0.2457 - val_loss: 8.1704 - val_acc: 0.2023\n",
      "Epoch 91/100\n",
      "73898/73898 [==============================] - 5s 71us/step - loss: 1.5590 - acc: 0.2459 - val_loss: 8.1610 - val_acc: 0.1651\n",
      "Epoch 92/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5544 - acc: 0.2482 - val_loss: 8.1824 - val_acc: 0.1679\n",
      "Epoch 93/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.5542 - acc: 0.2460 - val_loss: 8.2280 - val_acc: 0.2229\n",
      "Epoch 94/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5502 - acc: 0.2474 - val_loss: 8.2089 - val_acc: 0.2139\n",
      "Epoch 95/100\n",
      "73898/73898 [==============================] - 5s 69us/step - loss: 1.5481 - acc: 0.2481 - val_loss: 8.2055 - val_acc: 0.2044\n",
      "Epoch 96/100\n",
      "73898/73898 [==============================] - 5s 70us/step - loss: 1.5459 - acc: 0.2498 - val_loss: 8.2301 - val_acc: 0.2125\n",
      "Epoch 97/100\n",
      "73898/73898 [==============================] - 5s 73us/step - loss: 1.5438 - acc: 0.2478 - val_loss: 8.2306 - val_acc: 0.1716\n",
      "Epoch 98/100\n",
      "73898/73898 [==============================] - 7s 89us/step - loss: 1.5418 - acc: 0.2501 - val_loss: 8.2194 - val_acc: 0.1771\n",
      "Epoch 99/100\n",
      "73898/73898 [==============================] - 7s 88us/step - loss: 1.5405 - acc: 0.2484 - val_loss: 8.2456 - val_acc: 0.2215\n",
      "Epoch 100/100\n",
      "73898/73898 [==============================] - 6s 79us/step - loss: 1.5367 - acc: 0.2493 - val_loss: 8.2705 - val_acc: 0.1945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f48f0bb8048>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with the generated examples\n",
    "print(y_train_sub.shape, y_train_disease.shape)\n",
    "X_train, y_train = np.concatenate((X_train_sub, X_train_disease)), np.concatenate((y_train_sub, y_train_disease))\n",
    "\n",
    "classifier = Classifier(trainable=True, n_classes=15)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9125/9125 [==============================] - 0s 37us/step\n",
      "accuracy for regular diseases is 0.1907945205479452\n",
      "109/109 [==============================] - 0s 55us/step\n",
      "accuracy for novel disease 7 with generated examples is 0.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = classifier.evaluate(X_test_sub, y_test_sub)\n",
    "print('accuracy for regular diseases is {0}'.format(acc))\n",
    "\n",
    "loss, acc = classifier.evaluate(X_test_disease, y_test_disease)\n",
    "print('accuracy for novel disease {0} with generated examples is {1}'.format(disease_label_int, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
